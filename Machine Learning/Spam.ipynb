{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AxtS259u7jwH"
      },
      "source": [
        "# 2. Spam"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zk3s_gaeEK1B"
      },
      "source": [
        "Reporta el porcentaje de correos que están etiquetados como spam y como no spam en el conjunto de datos.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "D3jgy4J0iAme",
        "outputId": "136ada92-b846-4498-b5e0-21f6981ce9e0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "El porcentaje correos no spam es: 70.99768 %\n",
            "El porcentaje correos spam es: 29.00232 %\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np \n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "df = pd.read_csv('http://turing.iimas.unam.mx/~gibranfp/cursos/aprendizaje_automatizado/data/spam.csv', delim_whitespace=' ', header=None)\n",
        "data = df.to_numpy()\n",
        "\n",
        "# prior values without *1000\n",
        "data_d = data[data[:, -1] == 0] # No spam\n",
        "no_spam = data_d[:, :-1]\n",
        "p1 = ((len(no_spam)*100)/len(data))\n",
        "print(\"El porcentaje correos no spam es: {} %\".format(round(p1,5)))\n",
        "\n",
        "data_i = data[data[:, -1] == 1] #Spam\n",
        "spam = data_i[:, :-1]\n",
        "p2 = ((len(spam)*100)/len(data))\n",
        "print(\"El porcentaje correos spam es: {} %\".format(round(p2,5)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "znlsaUBhPFNU"
      },
      "source": [
        "Divide aleatoriamente el conjunto de datos en el 60 % para entrenamiento, el 20 % para validación\n",
        "y el 20 % restante para prueba usando 0 como semilla para tu generador de números\n",
        "aleatorios"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zPt2Zps0ZoN5",
        "outputId": "eb440cb0-4da6-48be-f326-fb2378ade8ed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Splited data: 3103 (60%), 1034(20%), 1035(20%)\n"
          ]
        }
      ],
      "source": [
        "np.random.seed(0)\n",
        "\n",
        "# shuffle the dataset\n",
        "np.random.shuffle(data)\n",
        "shape = data.shape[0]\n",
        "\n",
        "#Split data 60, 20 y 20\n",
        "shape_train, shape_test = int(shape*.6), int(shape*.2) # int convertion to avoid slice index error \n",
        "\n",
        "train_data, test_data, val_data = data[:shape_train,], data[shape_train:shape_train + shape_test,], data[shape_train + shape_test:,] #100% of the data\n",
        "\n",
        "train_data.shape[0], test_data.shape[0], val_data.shape[0]\n",
        "\n",
        "print(\"Splited data: {} (60%), {}(20%), {}(20%)\".format(train_data.shape[0],test_data.shape[0],val_data.shape[0]))\n",
        "\n",
        "#Spam and no spam selection\n",
        "data_spam = train_data[train_data[:, -1] == 1]\n",
        "data_no_spam = train_data[train_data[:, -1] == 0]\n",
        "\n",
        "#remove last column for convenience\n",
        "x_spam = data_spam[:, :-1]\n",
        "x_no_spam = data_no_spam[:, :-1]\n",
        "\n",
        "#x_spam.shape[0], x_no_spam.shape[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sdWPU_6R_ePN"
      },
      "source": [
        "### Entrena 2 clasificadores bayesianos ingenuos con distintas distribuciones\n",
        "##### Clasificador bayesiano ingenuo para distribución multinomial\n",
        "\n",
        "#### 1. Multinomial\n",
        "Estimamos la a priori \\\\\n",
        "Asumimos que la clases se distribuyen como una Bernoulli donde la estimación del parámetro $\\hat{q}_C$ se reduce al conteo de frecuencia de la clase en los datos:\n",
        "\n",
        "$$ \\hat{q}_C = \\frac{N_C}{N}$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QZKQ4W7IsGnx"
      },
      "outputs": [],
      "source": [
        "# previously calculadted on cell 1\n",
        "q_spam, q_no_spam = 0.7099768, 0.2900232"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DE4wr_wfs33U"
      },
      "source": [
        "###### Verosimilitud \n",
        "Asumimos que los atributos de distribuyen como multinomiales; El estimado de cada parámetro es la frecuencia de la palabra en la clase ignorando el termino de normalización:\n",
        "\n",
        "$$\\hat{q}(w_{t}|C) = \\frac{n_C(w_t)}{\\sum_{w}^{} n_C(w_t)}$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aAcVFHAXEK1I",
        "outputId": "0036c0aa-caca-4195-f5b0-84ea2e6f26ab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1.33238866e-02 6.49465667e-03 1.67286611e-03 ... 9.84038889e-05\n",
            " 1.57446222e-04 2.36169333e-04] [1.81731985e-03 2.25754018e-05 0.00000000e+00 ... 2.25754018e-05\n",
            " 2.25754018e-05 2.25754018e-05]\n"
          ]
        }
      ],
      "source": [
        "#Params estimation\n",
        "\n",
        "#occurrences ffor spam\n",
        "v_spam_w = x_spam.sum(axis=0) \n",
        "\n",
        "#occurrences for No spam\n",
        "v_nospam_w = x_no_spam.sum(axis=0) \n",
        "\n",
        "param_spam = v_spam_w / v_spam_w.sum()\n",
        "param_no_spam = v_nospam_w / v_nospam_w.sum()\n",
        "\n",
        "print(param_spam,param_no_spam)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SQPdiGkJEK1K"
      },
      "source": [
        "##### Clasificación"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "edYOHCGIEK1K"
      },
      "source": [
        "Recordemos que para clasificar en el modelo bayseiano ingenuo debemos computar:\n",
        "\n",
        "$$ P(n|s) = \\prod_{t=1}^{|V|} q(w_{t}|d)^{x_t} P (d)$$\n",
        "\n",
        "$$ P(n|i) = \\prod_{t=1}^{|V|} q(w_{t}|i)^{x_t} P (i)$$\n",
        "\n",
        "$$C = \\operatorname*{max} \\bigg\\{ P(n | d), P(n | i) \\bigg\\} $$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aZ0kOwzY0zBG"
      },
      "source": [
        "Usando el logaritmo por conveniencia de los datos:\n",
        "$$ P(n|s) = \\prod_{t=1}^{|V|} q(w_{t}|s)^{x_t} P (s) \\propto \\sum _{t=1}^{|V|} x_t \\log q(w_{t}|s) + P(s)  $$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "imCJSCo64ueC"
      },
      "source": [
        "Creando una clase para predecir las clases de nuestros datos:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2PoSi32dEK1K"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Mi compañera sofia me oriento en esta parte, ella encontro una solucion (ya que algunos \n",
        "parametros daban 0), sumandole una variable aux para que el log no tienda a ∞ \n",
        "\"\"\"\n",
        "class MultinomialBN():\n",
        "  \n",
        "  aux =0.0000000000001\n",
        "  binary_classes =[1, 0]\n",
        "  classes = ['spam','no_spam']\n",
        "\n",
        "  def predict_spam(self,x) :\n",
        "    return (np.log(self.aux+param_spam) * x).sum() + np.log(q_spam)\n",
        "\n",
        "  def predict_no_spam(self,x) : \n",
        "    return (np.log(self.aux+param_no_spam) * x).sum() + np.log(q_no_spam)\n",
        "\n",
        "  def classify(self,x):\n",
        "    return int(self.binary_classes[np.argmax([self.predict_spam(x), self.predict_no_spam(x)])])\n",
        "  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pKP4n4rC8ABb"
      },
      "source": [
        "Resultados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KFh-dY3n7_wI",
        "outputId": "0f74e1e2-d1c8-4860-c594-62d5be82212f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Exito en el conjunto de entremaniento: 96.777%\n",
            "Exito en el conjunto de validación: 97.198%\n",
            "Exito en el conjunto de prueba: 96.809%\n"
          ]
        }
      ],
      "source": [
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "  classifier = MultinomialBN()\n",
        "  train_loop = []\n",
        "  val_loop = []\n",
        "  test_loop = []\n",
        "\n",
        "  #vectors with our predictions\n",
        "  for i in train_data[:,:-1]:\n",
        "    train_loop.append(classifier.classify(i))\n",
        "\n",
        "  for j in val_data[:,:-1]:\n",
        "    val_loop.append(classifier.classify(j))\n",
        "\n",
        "  for k in test_data[:,:-1]:\n",
        "    test_loop.append(classifier.classify(k))\n",
        "\n",
        "  #Compare my predictions with subsets\n",
        "  train_success = np.mean((train_loop == train_data[:,-1]))\n",
        "  validation_success = np.mean(val_loop == val_data[:,-1])\n",
        "  test_sucess = np.mean(test_loop == test_data[:,-1])\n",
        "\n",
        "  print('Exito en el conjunto de entremaniento: {}%'.format((train_success*100).round(3)))\n",
        "  print('Exito en el conjunto de validación: {}%'.format((validation_success*100).round(3)))\n",
        "  print('Exito en el conjunto de prueba: {}%'.format((test_sucess*100).round(3)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XdkwplH_7I_W"
      },
      "source": [
        "# Spam (Bernoulli)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QQyTE2wq8OsV"
      },
      "source": [
        "##### Clasificación\n",
        "Para el segundo caso utilizaremos una debernouli, en donde todo es igual hasta los valores de la apriori. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "He4CzCg4DlmV"
      },
      "source": [
        "Suponemos los aributos con distribución de Bernoulli y stimamos las ocurrencias de la palabra en cada clase:\n",
        "\n",
        "$$\\hat{q}(w_{t}|C) = \\frac{n_C(w_t)}{\\sum_{w}^{} n_C(w_t)}$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uS7QhXVp8Oe4",
        "outputId": "14016b13-f92c-45fe-d1af-ce63ec421035"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.0113622  0.00533328 0.00183397 ... 0.0001054  0.00018972 0.00027404] [1.65855224e-03 0.00000000e+00 0.00000000e+00 ... 2.14006741e-05\n",
            " 1.07003371e-05 3.21010112e-05]\n"
          ]
        }
      ],
      "source": [
        "#occurrences ffor spam\n",
        "spam_w = x_spam.sum(axis=0) \n",
        "\n",
        "#occurrences for No spam\n",
        "nospam_w = x_no_spam.sum(axis=0) \n",
        "\n",
        "param_spam_b = spam_w / spam_w.sum()\n",
        "param_no_spam_b = nospam_w / nospam_w.sum()\n",
        "\n",
        "print(param_spam_b,param_no_spam_b)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ts4TCsJiM1AB"
      },
      "source": [
        "Utilizando nuevamente el logaritmo \n",
        "$$ P(x|C) \\propto \\sum_{t=1}^{|V|} x_t \\ln q + \\sum_{t=1}^{|V|}(1-x_t) \\ln (1-q) + \\ln P(C)$$\n",
        "\n",
        "\n",
        "$$C = \\operatorname*{max} \\bigg\\{ P(n | s), P(n | noSpam) \\bigg\\} $$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sea0q_8lM6Tb"
      },
      "outputs": [],
      "source": [
        "class BernoulliBN():\n",
        "  \n",
        "  aux =0.0000000000001\n",
        "  binary_classes =[1, 0]\n",
        "  classes = ['spam','no_spam']\n",
        "\n",
        "  def predict_spam(self,x) :\n",
        "    return (np.log(self.aux+param_spam) * x).sum() + (np.log(1 - (self.aux + param_spam_b)) * (1-x)).sum() + np.log(q_spam)\n",
        "\n",
        "  def predict_no_spam(self,x) : \n",
        "    return (np.log(self.aux+param_no_spam) * x).sum() + (np.log(1 - (self.aux + param_no_spam_b)) * (1-x)).sum() + np.log(q_no_spam)\n",
        "\n",
        "  def classify(self,x):\n",
        "    return int(self.binary_classes[np.argmax([self.predict_spam(x), self.predict_no_spam(x)])])\n",
        "  \n",
        "  def train_function():"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d2eKz017M-tX",
        "outputId": "d746a3ed-b294-4183-fa43-2f91d8fa8d91"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Exito en el conjunto de entremaniento: 96.971%\n",
            "Exito en el conjunto de validación: 96.329%\n",
            "Exito en el conjunto de prueba: 97.099%\n"
          ]
        }
      ],
      "source": [
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "  classifier = BernoulliBN()\n",
        "  train_loop = []\n",
        "  val_loop = []\n",
        "  test_loop = []\n",
        "\n",
        "  #vectors with our predictions\n",
        "  for i in train_data[:,:-1]:\n",
        "    train_loop.append(classifier.classify(i))\n",
        "\n",
        "  for j in val_data[:,:-1]:\n",
        "    val_loop.append(classifier.classify(j))\n",
        "\n",
        "  for k in test_data[:,:-1]:\n",
        "    test_loop.append(classifier.classify(k))\n",
        "\n",
        "  #Compare my predictions with subsets\n",
        "  train_success = np.mean((train_loop == train_data[:,-1]))\n",
        "  validation_success = np.mean(val_loop == val_data[:,-1])\n",
        "  test_sucess = np.mean(test_loop == test_data[:,-1])\n",
        "\n",
        "  print('Exito en el conjunto de entremaniento: {}%'.format((train_success*100).round(3)))\n",
        "  print('Exito en el conjunto de validación: {}%'.format((validation_success*100).round(3)))\n",
        "  print('Exito en el conjunto de prueba: {}%'.format((test_sucess*100).round(3)))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Spam.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}